version: "3.7"

#
# Solr shard base service
# =======================
#
# Solr shards are not easily replicatable (because resharding would have to be
# done manually), also every Solr shard has to have its very own named volume
# to write the data to, so instead of replicating Solr shards with
# "deploy/replicas", we define every shard as its own independent service.
#
x-solr-shard_base:   &solr-shard_base
    build:
        context: ./solr-shard/
    image: dockermediacloud/solr-shard:release
    env_file: global.env
    environment:
        # Shard count (every individual shard needs to know the total count)
        #
        # (keep in sync with how many shard services get actually defined in
        # the "services" section, e.g. solr-shard_01, solr-shard_02,
        # ..., solr-shard_24)
        MC_SOLR_SHARD_COUNT: "24"
    depends_on:
        - solr-zookeeper
    expose:
        - 8983
    networks:
        default:
            aliases:
                # To make Solr clients be able to round-robin between the
                # shards, all of the shard services get assigned the same
                # "solr-shard" network alias.
                - solr-shard
    deploy:
        # Every shard runs as its own independent, non-replicated service
        resources:
            limits:
                # CPU core limit
                #
                # (each mcquery* has 32 cores and will be running 8 shards
                # each, so 32 / 8 = 4)
                cpus: "4"
                # RAM limit
                #
                # (each mcquery* has 192 GB of RAM and will be running 8 shards
                # each, so 192 / 8 = 24)
                memory: 24G


#
# Services
# ========
#
services:

    #
    # CLIFF fetch annotation
    # ----------------------
    #
    cliff-fetch-annotation:
        build:
            context: ./cliff-fetch-annotation/
        image: dockermediacloud/cliff-fetch-annotation:release
        networks:
            - default
        env_file: global.env
        environment:
            # Annotator endpoint URL
            MC_CLIFF_ANNOTATOR_URL: ""
        depends_on:
            - extract-and-vector
            - postgresql-pgbouncer
            - rabbitmq-server
        deploy:
            # Worker count
            replicas: 4
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # CLIFF update story tags
    # -----------------------
    #
    cliff-update-story-tags:
        build:
            context: ./cliff-update-story-tags/
        image: dockermediacloud/cliff-update-story-tags:release
        networks:
            - default
        env_file: global.env
        environment:
            # CLIFF version tag
            MC_CLIFF_VERSION_TAG: "cliff_clavin_v2.4.1"
            # Tag set to use for geographical name entities
            MC_CLIFF_GEONAMES_TAG_SET: "cliff_geonames"
            # Tag set to use for organization name entities
            MC_CLIFF_ORGANIZATIONS_TAG_SET: "cliff_organizations"
            # Tag set to use for person name entities
            MC_CLIFF_PEOPLE_TAG_SET: "cliff_people"
        depends_on:
            - cliff-fetch-annotation
            - postgresql-pgbouncer
            - rabbitmq-server
        deploy:
            # Worker count
            replicas: 1
            # Auto-restart on crashes
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Crawler provider
    # ----------------
    #
    crawler-provider:
        build:
            context: ./crawler-provider/
        image: dockermediacloud/crawler-provider:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - postgresql-pgbouncer
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 1G

    #
    # Crawler fetcher
    # ---------------
    #
    crawler-fetcher:
        build:
            context: ./crawler-fetcher/
        image: dockermediacloud/crawler-fetcher:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - postgresql-pgbouncer
            - rabbitmq-server
        deploy:
            # Worker count
            replicas: 8
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Create missing PostgreSQL partitions
    # ------------------------------------
    #
    create-missing-partitions:
        build:
            context: ./create-missing-partitions/
        image: dockermediacloud/create-missing-partitions:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - postgresql-pgbouncer
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256G

    #
    # Extract article HTML from page HTML
    # -----------------------------------
    #
    extract-article-from-page:
        build:
            context: ./extract-article-from-page/
        image: dockermediacloud/extract-article-from-page:release
        networks:
            - default
        env_file: global.env
        deploy:
            # Worker count
            replicas: 8
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Extract and vector stories
    # --------------------------
    #
    extract-and-vector:
        build:
            context: ./extract-and-vector/
        image: dockermediacloud/extract-and-vector:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - extract-article-from-page
            - postgresql-pgbouncer
            - rabbitmq-server
        deploy:
            # Worker count
            replicas: 24
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Fetch story stats from Facebook
    # -------------------------------
    #
    facebook-fetch-story-stats:
        build:
            context: ./facebook-fetch-story-stats/
        image: dockermediacloud/facebook-fetch-story-stats:release
        networks:
            - default
        env_file: global.env
        environment:
            # Facebook application ID
            MC_FACEBOOK_APP_ID: ""
            # Facebook application secret
            MC_FACEBOOK_APP_SECRET: ""
            # Timeout for API calls
            MC_FACEBOOK_TIMEOUT: "60"
        depends_on:
            - extract-and-vector
            - postgresql-pgbouncer
            - rabbitmq-server
        deploy:
            # Worker count
            replicas: 4
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Generate daily RSS dumps Cron job
    # ---------------------------------
    #
    cron-generate-daily-rss-dumps:
        build:
            context: ./cron-generate-daily-rss-dumps/
        image: dockermediacloud/cron-generate-daily-rss-dumps:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - postgresql-pgbouncer
        volumes:
            # Shared with "webapp-httpd" container:
            - vol_daily_rss_dumps:/var/lib/daily_rss_dumps/
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 1G

    #
    # Generate media health report Cron job
    # -------------------------------------
    #
    cron-generate-media-health:
        build:
            context: ./cron-generate-media-health/
        image: dockermediacloud/cron-generate-media-health:release
        networks:
            - default
        env_file: global.env
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Generate daily / weekly user summary Cron job
    # ---------------------------------------------
    #
    cron-generate-user-summary:
        build:
            context: ./cron-generate-user-summary/
        image: dockermediacloud/cron-generate-user-summary:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - postgresql-pgbouncer
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Import stories into Solr
    # ------------------------
    #
    import-solr-data:
        build:
            context: ./import-solr-data/
        image: dockermediacloud/import-solr-data:release
        networks:
            - default
        env_file: global.env
        environment:
            # Jobs (forks) to start for the import
            # (keep in sync with CPU count)
            MC_SOLR_IMPORT_JOBS: 1
            # Stories to import into Solr on a single run
            MC_SOLR_IMPORT_MAX_QUEUED_STORIES: 100000
        depends_on:
            - postgresql-pgbouncer
            - solr-shard_01
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "16"
                    # RAM limit
                    memory: 4G

    #
    # Import stories by scraping Feedly
    # ---------------------------------
    #
    import-stories-feedly:
        build:
            context: ./import-stories-feedly/
        image: dockermediacloud/import-stories-feedly:release
        networks:
            - default
        env_file: global.env
        deploy:
            # Writes stories to PostgreSQL
            - net_postgresql
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit (uses quite a lot of it until it OOMs)
                    memory: 4G

    #
    # OpenDKIM server
    # ---------------
    #
    mail-opendkim-server:
        build:
            context: ./mail-opendkim-server/
        image: dockermediacloud/mail-opendkim-server:release
        networks:
            - default
        env_file: global.env
        environment:
            # Top-level domain to use for signing emails, e.g. "mediacloud.org"
            # (keep in sync with MC_MAIL_POSTFIX_DOMAIN)
            MC_MAIL_OPENDKIM_DOMAIN: "testmediacloud.ml"
            # Mail server hostname, e.g. "mail" for "mail.mediacloud.org"
            # (keep in sync with MC_MAIL_POSTFIX_HOSTNAME)
            MC_MAIL_OPENDKIM_HOSTNAME: "mail"
        ports:
            # Expose OpenDKIM to host computer
            - "12301"
        volumes:
            - vol_opendkim_config:/etc/opendkim/
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 128M

    #
    # Postfix server
    # ---------------
    #
    mail-postfix-server:
        build:
            context: ./mail-postfix-server/
        image: dockermediacloud/mail-postfix-server:release
        networks:
            - default
        env_file: global.env
        environment:
            # Top-level domain to use for signing emails, e.g. "mediacloud.org"
            # (keep in sync with MC_MAIL_OPENDKIM_DOMAIN)
            MC_MAIL_POSTFIX_DOMAIN: "testmediacloud.ml"
            # Mail server hostname, e.g. "mail" for "mail.mediacloud.org"
            # (keep in sync with MC_MAIL_OPENDKIM_HOSTNAME)
            MC_MAIL_POSTFIX_HOSTNAME: "mail"
        expose:
            # Expose SMTP to mail senders
            - "25"
        volumes:
            - vol_postfix_data:/var/spool/postfix/
            - vol_postfix_local_mail:/var/lib/mail/
            - vol_postfix_queue:/var/spool/postfix/
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 128M

    #
    # NYTLabels fetch annotation
    # ----------------------
    #
    nytlabels-fetch-annotation:
        build:
            context: ./nytlabels-fetch-annotation/
        image: dockermediacloud/nytlabels-fetch-annotation:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - extract-and-vector
            - predict-news-labels
            - postgresql-pgbouncer
            - rabbitmq-server
        deploy:
            # Worker count
            replicas: 4
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # NYTLabels update story tags
    # -----------------------
    #
    nytlabels-update-story-tags:
        build:
            context: ./nytlabels-update-story-tags/
        image: dockermediacloud/nytlabels-update-story-tags:release
        networks:
            - default
        env_file: global.env
        environment:
            # NYTLabels version tag
            MC_NYTLABELS_VERSION_TAG: "nyt_labeller_v1.0.0"
            # Tag set to use for NYTLabels-derived tags
            MC_NYTLABELS_TAG_SET: "nyt_labels"
        depends_on:
            - nytlabels-fetch-annotation
            - postgresql-pgbouncer
            - rabbitmq-server
        deploy:
            # Worker count
            replicas: 1
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # PgBouncer
    # ---------
    #
    postgresql-pgbouncer:
        build:
            context: ./postgresql-pgbouncer/
        image: dockermediacloud/postgresql-pgbouncer:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - postgresql-server
        expose:
            - 6432

    #
    # PostgreSQL server
    # -----------------
    #
    postgresql-server:
        build:
            context: ./postgresql-server/
        image: dockermediacloud/postgresql-server:release
        networks:
            - default
        env_file: global.env
        expose:
            - 5432
        volumes:
            - vol_postgresql_data:/var/lib/postgresql/

    #
    # NYT-Based News Tagger service
    # -----------------------------
    #
    predict-news-labels:
        build:
            context: ./predict-news-labels/
        image: dockermediacloud/predict-news-labels:release
        networks:
            - default
        env_file: global.env
        expose:
            - 80
        deploy:
            # Worker count
            replicas: 1
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 8G

    #
    # Purge PostgreSQL object caches
    # ------------------------------------
    #
    purge-object-caches:
        build:
            context: ./purge-object-caches/
        image: dockermediacloud/purge-object-caches:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - postgresql-pgbouncer
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256G

    #
    # RabbitMQ
    # --------
    #
    rabbitmq-server:
        build:
            context: ./rabbitmq-server/
        image: dockermediacloud/rabbitmq-server:release
        networks:
            - default
        env_file: global.env
        expose:
            - 5672
            - 15672
        volumes:
            - vol_rabbitmq_data:/var/lib/rabbitmq/
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "4"
                    # RAM limit
                    memory: 8G

    #
    # Refresh stats Cron job
    # ----------------------
    #
    cron-refresh-stats:
        build:
            context: ./cron-refresh-stats/
        image: dockermediacloud/cron-refresh-stats:release
        networks:
            - default
        env_file: global.env
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Add due media to the rescraping queue Cron job
    # ----------------------------------------------
    #
    cron-rescrape-due-media:
        build:
            context: ./cron-rescrape-due-media/
        image: dockermediacloud/cron-rescrape-due-media:release
        networks:
            - default
        env_file: global.env
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # (Re)scrape media
    # ----------------
    #
    rescrape-media:
        build:
            context: ./rescrape-media/
        image: dockermediacloud/rescrape-media:release
        networks:
            - default
        env_file: global.env
        deploy:
            # Worker count
            replicas: 2
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Report rescraping changes Cron job
    # ----------------------------------
    #
    cron-rescraping-changes:
        build:
            context: ./cron-rescraping-changes/
        image: dockermediacloud/cron-rescraping-changes:release
        networks:
            - default
        env_file: global.env
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Set media primary language Cron job
    # -----------------------------------
    #
    cron-set-media-primary-language:
        build:
            context: ./cron-set-media-primary-language/
        image: dockermediacloud/cron-set-media-primary-language:release
        networks:
            - default
        env_file: global.env
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Set media subject country Cron job
    # -----------------------------------
    #
    cron-set-media-subject-country:
        build:
            context: ./cron-set-media-subject-country/
        image: dockermediacloud/cron-set-media-subject-country:release
        networks:
            - default
        env_file: global.env
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Print long running job states
    # -----------------------------
    #
    cron-print-long-running-job-states:
        build:
            context: ./cron-print-long-running-job-states/
        image: dockermediacloud/cron-print-long-running-job-states:release
        networks:
            - default
        env_file: global.env
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Solr shards 01-24
    # -----------------
    #
    solr-shard_01:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_01:/var/lib/solr/

    solr-shard_02:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_02:/var/lib/solr/

    solr-shard_03:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_03:/var/lib/solr/

    solr-shard_04:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_04:/var/lib/solr/

    solr-shard_05:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_05:/var/lib/solr/

    solr-shard_06:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_06:/var/lib/solr/

    solr-shard_07:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_07:/var/lib/solr/

    solr-shard_08:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_08:/var/lib/solr/

    solr-shard_09:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_09:/var/lib/solr/

    solr-shard_10:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_10:/var/lib/solr/

    solr-shard_11:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_11:/var/lib/solr/

    solr-shard_12:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_12:/var/lib/solr/

    solr-shard_13:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_13:/var/lib/solr/

    solr-shard_14:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_14:/var/lib/solr/

    solr-shard_15:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_15:/var/lib/solr/

    solr-shard_16:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_16:/var/lib/solr/

    solr-shard_17:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_17:/var/lib/solr/

    solr-shard_18:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_18:/var/lib/solr/

    solr-shard_19:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_19:/var/lib/solr/

    solr-shard_20:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_20:/var/lib/solr/

    solr-shard_21:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_21:/var/lib/solr/

    solr-shard_22:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_22:/var/lib/solr/

    solr-shard_23:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_23:/var/lib/solr/

    solr-shard_24:
        <<: *solr-shard_base
        volumes:
            - vol_solr_shard_data_24:/var/lib/solr/

    #
    # Solr ZooKeeper
    # --------------
    #
    solr-zookeeper:
        build:
            context: ./solr-zookeeper/
        image: dockermediacloud/solr-zookeeper:release
        networks:
            - default
        env_file: global.env
        expose:
            - 2181
            - 2888
            - 3888
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Extract story links for a topic
    # -------------------------------
    #
    topics-extract-story-links:
        build:
            context: ./topics-extract-story-links/
        image: dockermediacloud/topics-extract-story-links:release
        networks:
            - default
        env_file: global.env
        depends_on:
            - extract-article-from-page
        deploy:
            # Worker count
            replicas: 32
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Fetch link for a topic
    # ----------------------
    #
    topics-fetch-link:
        build:
            context: ./topics-fetch-link/
        image: dockermediacloud/topics-fetch-link:release
        networks:
            - default
        env_file: global.env
        deploy:
            # Worker count
            replicas: 8
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Fetch Twitter URLs
    # ------------------
    #
    topics-fetch-twitter-urls:
        build:
            context: ./topics-fetch-twitter-urls/
        image: dockermediacloud/topics-fetch-twitter-urls:release
        networks:
            - default
        env_file: global.env
        environment:
            # Twitter API consumer key
            MC_TWITTER_CONSUMER_KEY: ""
            # Twitter API consumer secret
            MC_TWITTER_CONSUMER_SECRET: ""
            # Twitter API access token
            MC_TWITTER_ACCESS_TOKEN: ""
            # Twitter API access token secret
            MC_TWITTER_ACCESS_TOKEN_SECRET: ""
        deploy:
            # Worker count
            replicas: 8
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Mine a topic
    # ------------
    #
    topics-mine:
        build:
            context: ./topics-mine/
        image: dockermediacloud/topics-mine:release
        networks:
            - default
        env_file: global.env
        environment:
            # Crimson Hexagon API key
            MC_CRIMSON_HEXAGON_API_KEY: ""
        deploy:
            # Worker count
            replicas: 4
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Mine a public topic
    # -------------------
    #
    topics-mine-public:
        build:
            context: ./topics-mine-public/
        image: dockermediacloud/topics-mine-public:release
        networks:
            - default
        env_file: global.env
        environment:
            # Crimson Hexagon API key
            MC_CRIMSON_HEXAGON_API_KEY: ""
        deploy:
            # Worker count
            replicas: 4
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Snapshot a topic
    # ----------------
    #
    topics-snapshot:
        build:
            context: ./topics-snapshot/
        image: dockermediacloud/topics-snapshot:release
        networks:
            - default
        env_file: global.env
        environment:
            # Not sure what this is.
            MC_TOPICS_SNAPSHOT_MODEL_REPS: "0"
        deploy:
            # Worker count
            replicas: 2
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Munin node
    # ----------
    #
    munin-node:
        build:
            context: ./munin-node/
        image: dockermediacloud/munin-node:release
        networks:
            - default
        depends_on:
            # Monitors data on PostgreSQL
            - postgresql-pgbouncer
            # Monitors data on Solr
            - solr-shard_01
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Munin Cron stats collector
    # --------------------------
    #
    munin-cron:
        build:
            context: ./munin-cron/
        image: dockermediacloud/munin-cron:release
        networks:
            - default
        depends_on:
            # Reads data from Munin node
            - munin-node
        volumes:
            # Shared with "munin_httpd" container:
            - vol_munin_data:/var/lib/munin/
            # Shared with "munin_httpd" container:
            - vol_munin_html:/var/cache/munin/www/
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Munin HTTP server
    # -----------------
    #
    munin-httpd:
        build:
            context: ./munin-httpd/
        image: dockermediacloud/munin-httpd:release
        networks:
            - default
        depends_on:
            # Reads data generated by Munin stats collector
            - munin-cron
        volumes:
            # Shared with "munin_httpd" container:
            - vol_munin_data:/var/lib/munin/
            # Shared with "munin_httpd" container:
            - vol_munin_html:/var/cache/munin/www/
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Fetch sitemap pages from media
    # ------------------------------
    #
    sitemap-fetch-media-pages:
        build:
            context: ./sitemap-fetch-media-pages/
        image: dockermediacloud/sitemap-fetch-media-pages:release
        networks:
            - default
        env_file: global.env
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Webapp (Plackup FastCGI workers)
    # --------------------------------
    #
    webapp-api:
        build:
            context: ./webapp-api/
        image: dockermediacloud/webapp-api:release
        networks:
            - default
        expose:
            # Plackup FastCGI worker port to be used by webapp_httpd
            - "9090"
        deploy:
            # FastCGI workers
            replicas: 8
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 1G

    #
    # Webapp (HTTP server)
    # --------------------
    #
    webapp-httpd:
        build:
            context: ./webapp-httpd/
        image: dockermediacloud/webapp-httpd:release
        networks:
            - default
        expose:
            # Expose HTTP port to reverse proxy
            - "80"
        volumes:
            # Shared with "cron_generate_daily_rss_dumps" container:
            - vol_daily_rss_dumps:/mediacloud_webapp_static/rss_dumps/
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Cron job that updates Let's Encrypt certificates used by reverse proxy
    # ----------------------------------------------------------------------
    #
    proxy-cron-certbot:
        build:
            context: ./proxy-cron-certbot/
        image: dockermediacloud/proxy-cron-certbot:release
        networks:
            - default
        environment:
            # Top-level domain to issue the certificate for
            MC_PROXY_CERTBOT_DOMAIN: "testmediacloud.ml"
            # Email for Let's Encrypt's notifications
            MC_PROXY_CERTBOT_LETSENCRYPT_EMAIL: "linas@media.mit.edu"
            # CloudFlare account email
            MC_PROXY_CERTBOT_CLOUDFLARE_EMAIL: ""
            # CloudFlare account global API key
            MC_PROXY_CERTBOT_CLOUDFLARE_GLOBAL_API_KEY: ""
        volumes:
            # Shared with "proxy_httpd" container:
            - vol_proxy_ssl_certs:/etc/letsencrypt/
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # SSL terminating reverse proxy
    # -----------------------------
    #
    proxy-httpd:
        build:
            context: ./proxy-httpd/
        image: dockermediacloud/proxy-httpd:release
        networks:
            - default
        environment:
            # Semicolon-separated user credentials for restricted webapps
            # (Munin and Portainer); usernames and passwords separated by a
            # colon, e.g.:
            #
            #     "username1:password1;username2:password2;username3:password3"
            #
            MC_PROXY_HTTPD_AUTH_USERS: ""
        ports:
            # HTTP and HTTPS ports
            - "80"
            - "443"
        volumes:
            # Shared with "proxy_cron_certbot" container:
            - vol_proxy_ssl_certs:/etc/letsencrypt/
        depends_on:
            # Requires SSL certificate to run
            - proxy-cron-certbot
            # Proxies to main app
            - webapp-httpd
            # Proxies to Munin's web interface
            - munin-httpd
            # Proxies to Portainer's web UI
            - portainer
        deploy:
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Generate word2vec snapshot model
    # ----------------
    #
    word2vec-generate-snapshot-model:
        build:
            context: ./word2vec-generate-snapshot-model/
        image: dockermediacloud/word2vec-generate-snapshot-model:release
        networks:
            - default
        env_file: global.env
        deploy:
            # Worker count
            replicas: 2
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Portainer for cluster management
    # --------------------------------
    #
    portainer:
       image: portainer/portainer:1.20.2
        networks:
            - default
       expose:
           # Web interface
           - "9000:9000"
       command: -H unix:///var/run/docker.sock
       volumes:
           - /var/run/docker.sock:/var/run/docker.sock
           - vol_portainer_data:/data
       deploy:
           resources:
               limits:
                   # CPU core limit
                   cpus: "1"
                   # RAM limit
                   memory: 1G


#
# Networks
# ========
#
networks:

    # Just throw anything to this network. Typically we wouldn't have to even
    # define it here, but some services use aliases so every service has to be
    # explicitly added to some sort of a network.
    default:


#
# Volumes
# =======
#
volumes:

    # PostgreSQL server's data
    vol_postgresql_data: {}

    # Solr shard's data
    vol_solr_shard_data_01: {}
    vol_solr_shard_data_02: {}
    vol_solr_shard_data_03: {}
    vol_solr_shard_data_04: {}
    vol_solr_shard_data_05: {}
    vol_solr_shard_data_06: {}
    vol_solr_shard_data_07: {}
    vol_solr_shard_data_08: {}
    vol_solr_shard_data_09: {}
    vol_solr_shard_data_10: {}
    vol_solr_shard_data_11: {}
    vol_solr_shard_data_12: {}
    vol_solr_shard_data_13: {}
    vol_solr_shard_data_14: {}
    vol_solr_shard_data_15: {}
    vol_solr_shard_data_16: {}
    vol_solr_shard_data_17: {}
    vol_solr_shard_data_18: {}
    vol_solr_shard_data_19: {}
    vol_solr_shard_data_20: {}
    vol_solr_shard_data_21: {}
    vol_solr_shard_data_22: {}
    vol_solr_shard_data_23: {}
    vol_solr_shard_data_24: {}

    # RabbitMQ data
    vol_rabbitmq_data: {}

    # OpenDKIM configuration and keys
    vol_opendkim_config: {}

    # Postfix data
    vol_postfix_data: {}

    # Postfix local mail
    vol_postfix_local_mail: {}

    # Postfix mail queue
    vol_postfix_queue: {}

    # Daily RSS dumps
    # (shared between cron_generate_daily_rss_dumps and webapp-httpd)
    vol_daily_rss_dumps: {}

    # Munin's RRD data
    # (shared between munin_cron and munin_httpd)
    vol_munin_data: {}

    # Munin's generated HTML files
    # (shared between munin_cron and munin_httpd)
    vol_munin_html: {}

    # Let's Encrypt certificates
    vol_proxy_ssl_certs: {}

    # Portainer data
    vol_portainer_data: {}

