version: "3"

#
# Services
# ========
#
services:

    #
    # CLIFF fetch annotation
    # ----------------------
    #
    cliff_fetch_annotation:
        build:
            context: ./cliff-fetch-annotation/
        image: dockermediacloud/mediacloud-cliff-fetch-annotation:latest
        container_name: mc_cliff_fetch_annotation
        environment:
            # Annotator endpoint URL
            MC_CLIFF_ANNOTATOR_URL: ""
        depends_on:
            - extract_and_vector
            - postgresql_pgbouncer
            - rabbitmq_server
        networks:
            # Stores fetched raw annotation to PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 4
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # CLIFF update story tags
    # -----------------------
    #
    cliff_update_story_tags:
        build:
            context: ./cliff-update-story-tags/
        image: dockermediacloud/mediacloud-cliff-update-story-tags:latest
        container_name: mc_cliff_update_story_tags
        environment:
            # CLIFF version tag
            MC_CLIFF_VERSION_TAG: "cliff_clavin_v2.4.1"
            # Tag set to use for geographical name entities
            MC_CLIFF_GEONAMES_TAG_SET: "cliff_geonames"
            # Tag set to use for organization name entities
            MC_CLIFF_ORGANIZATIONS_TAG_SET: "cliff_organizations"
            # Tag set to use for person name entities
            MC_CLIFF_PEOPLE_TAG_SET: "cliff_people"
        depends_on:
            - cliff_fetch_annotation
            - postgresql_pgbouncer
            - rabbitmq_server
        networks:
            # Fetches raw annotation, stores tags to PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Crawler
    # -------
    #
    crawler:
        build:
            context: ./crawler/
        image: dockermediacloud/mediacloud-crawler:latest
        container_name: mc_crawler
        environment:
            # Univision API client ID
            MC_UNIVISION_CLIENT_ID: ""
            # Univision API client secret
            MC_UNIVISION_CLIENT_SECRET: ""
        depends_on:
            - postgresql_pgbouncer
            - rabbitmq_server
        networks:
            # Stores fetched data in PostgreSQL
            - net_postgresql
            # Adds extractor jobs
            - net_rabbitmq
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "16"
                    # RAM limit
                    memory: 64G

    #
    # Create missing PostgreSQL partitions
    # ------------------------------------
    #
    create_missing_partitions:
        build:
            context: ./create-missing-partitions/
        image: dockermediacloud/mediacloud-create-missing-partitions:latest
        container_name: mc_create_missing_partitions
        depends_on:
            - postgresql_pgbouncer
        networks:
            # Creates partitions on PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256G

    #
    # Extract article HTML from page HTML
    # -----------------------------------
    #
    extract_article_from_html:
        build:
            context: ./extract-article-from-html/
        image: dockermediacloud/mediacloud-extract-article-from-html:latest
        container_name: mc_extract_article_from_html
        deploy:
            # Worker count
            replicas: 8
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Extract and vector stories
    # --------------------------
    #
    extract_and_vector:
        build:
            context: ./extract-and-vector/
        image: dockermediacloud/mediacloud-extract-and-vector:latest
        container_name: mc_extract_and_vector
        depends_on:
            - extract_article_from_html
            - crawler
            - postgresql_pgbouncer
            - rabbitmq_server
        networks:
            # Fetches / stores extracted data to PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 24
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Fetch story stats from Facebook
    # -------------------------------
    #
    facebook_fetch_story_stats:
        build:
            context: ./facebook-fetch-story-stats/
        image: dockermediacloud/mediacloud-facebook-fetch-story-stats:latest
        container_name: mc_facebook_fetch_story_stats
        environment:
            # Facebook application ID
            MC_FACEBOOK_APP_ID: ""
            # Facebook application secret
            MC_FACEBOOK_APP_SECRET: ""
            # Timeout for API calls
            MC_FACEBOOK_TIMEOUT: "60"
        depends_on:
            - extract_and_vector
            - postgresql_pgbouncer
            - rabbitmq_server
        networks:
            # Stores Facebook stats in PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 4
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Generate daily RSS dumps Cron job
    # ---------------------------------
    #
    cron_generate_daily_rss_dumps:
        build:
            context: ./cron-generate-daily-rss-dumps/
        image: dockermediacloud/mediacloud-cron-generate-daily-rss-dumps:latest
        container_name: mc_cron_generate_daily_rss_dumps
        depends_on:
            - postgresql_pgbouncer
        networks:
            # Generates RSS report using data from PostgreSQL
            - net_postgresql
        volumes:
            # Shared with "webapp" container:
            - vol_daily_rss_dumps:/var/lib/daily_rss_dumps/
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 1G

    #
    # Generate media health report Cron job
    # -------------------------------------
    #
    cron_generate_media_health:
        build:
            context: ./cron-generate-media-health/
        image: dockermediacloud/mediacloud-cron-generate-media-health:latest
        container_name: mc_cron_generate_media_health
        networks:
            # Generates media health report from PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Generate daily / weekly user summary Cron job
    # ---------------------------------------------
    #
    cron_generate_user_summary:
        build:
            context: ./cron-generate-user-summary/
        image: dockermediacloud/mediacloud-cron-generate-user-summary:latest
        container_name: mc_cron_generate_user_summary
        depends_on:
            - postgresql_pgbouncer
        networks:
            # Reads users from PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Import stories into Solr
    # ------------------------
    #
    import_solr_data:
        build:
            context: ./import-solr-data/
        image: dockermediacloud/mediacloud-import-solr-data:latest
        container_name: mc_import_solr_data
        environment:
            # Stories to import into Solr on a single run
            MC_SOLR_IMPORT_MAX_QUEUED_STORIES: "100000"
        depends_on:
            - postgresql_pgbouncer
            - solr_shard
        networks:
            # Reads stories from PostgreSQL
            - net_postgresql
            # Imports stories to Solr
            - net_solr
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "16"
                    # RAM limit
                    memory: 4G

    #
    # Import stories into Solr for testing
    # ------------------------------------
    #
    # import_solr_data_for_testing:
    #     build:
    #         context: ./import-solr-data-for-testing/
    #     image: dockermediacloud/mediacloud-import-solr-data-for-testing:latest
    #     container_name: mc_import_solr_data_for_testing
    #     environment:
    #         # Stories to import into Solr on a single run
    #         MC_SOLR_IMPORT_MAX_QUEUED_STORIES: "100000"
    #     depends_on:
    #         - postgresql_pgbouncer
    #         - solr_shard
    #     networks:
    #         # Reads stories from PostgreSQL
    #         - net_postgresql
    #         # Imports stories to Solr
    #         - net_solr
    #     deploy:
    #         # Only one instance
    #         replicas: 1
    #         # Auto-restart on crashes
    #         restart_policy:
    #             condition: on-failure
    #         resources:
    #             limits:
    #                 # CPU core limit
    #                 cpus: "16"
    #                 # RAM limit
    #                 memory: 4G

    #
    # Scrape Feedly for new stories
    # -----------------------------
    #
    scrape_feedly:
        build:
            context: ./scrape-feedly/
        image: dockermediacloud/mediacloud-scrape-feedly:latest
        container_name: mc_scrape_feedly
        deploy:
            # Writes stories to PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit (uses quite a lot of it until it OOMs)
                    memory: 4G

    #
    # OpenDKIM server
    # ---------------
    #
    mail_opendkim_server:
        build:
            context: ./mail-opendkim-server/
        image: dockermediacloud/mediacloud-mail-opendkim-server:latest
        container_name: mc_mail_opendkim_server
        networks:
            # Accessed by Postfix only
            - net_postfix_opendkim
        # Expose OpenDKIM to host computer (so "ports" and not "expose")
        ports:
            - "12301"
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 128M

    #
    # Postfix server
    # ---------------
    #
    mail_postfix_server:
        build:
            context: ./mail-postfix-server/
        image: dockermediacloud/mediacloud-mail-postfix-server:latest
        container_name: mc_mail_postfix_server
        networks:
            # Exposed to the rest of the services through this network
            - net_postfix
            # Accesses underlying OpenDKIM instance
            - net_postfix_opendkim
        expose:
            # Expose SMTP to mail senders
            - "25"
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 128M

    #
    # NYTLabels fetch annotation
    # ----------------------
    #
    nytlabels_fetch_annotation:
        build:
            context: ./nytlabels-fetch-annotation/
        image: dockermediacloud/mediacloud-nytlabels-fetch-annotation:latest
        container_name: mc_nytlabels_fetch_annotation
        environment:
            # NYTLabels annotator endpoint URL
            MC_NYTLABELS_ANNOTATOR_URL: ""
        depends_on:
            - extract_and_vector
            - predict_news_labels
            - postgresql_pgbouncer
            - rabbitmq_server
        networks:
            # Accesses underlying NYT-Based News Tagger service
            - net_nytlabels_fetch_annotation_predict_news_labels
            # Stores fetched raw annotation to PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 4
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # NYTLabels update story tags
    # -----------------------
    #
    nytlabels_update_story_tags:
        build:
            context: ./nytlabels-update-story-tags/
        image: dockermediacloud/mediacloud-nytlabels-update-story-tags:latest
        container_name: mc_nytlabels_update_story_tags
        environment:
            # NYTLabels version tag
            MC_NYTLABELS_VERSION_TAG: "nyt_labeller_v1.0.0"
            # Tag set to use for NYTLabels-derived tags
            MC_NYTLABELS_TAG_SET: "nyt_labels"
        depends_on:
            - nytlabels_fetch_annotation
            - postgresql_pgbouncer
            - rabbitmq_server
        networks:
            # Fetches raw annotation, stores tags to PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # PgBouncer
    # ---------
    #
    postgresql_pgbouncer:
        build:
            context: ./postgresql-pgbouncer/
        image: dockermediacloud/mediacloud-postgresql-pgbouncer:latest
        container_name: mc_postgresql_pgbouncer
        depends_on:
            - postgresql_server
        networks:
            # Exposed to the rest of the services through this network
            - net_postgresql
            # Accesses underlying PostgreSQL instance
            - net_postgresql_pgbouncer
        expose:
            - 6432
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure

    #
    # PostgreSQL server
    # -----------------
    #
    postgresql_server:
        build:
            context: ./postgresql-server/
        image: dockermediacloud/mediacloud-postgresql-server:latest
        container_name: mc_postgresql_server
        networks:
            # Not in "net_postgresql" because accessed through PgBouncer
            - net_postgresql_pgbouncer
        expose:
            - 5432
        volumes:
            - vol_postgresql_data:/var/lib/postgresql/11/main/
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure

    #
    # NYT-Based News Tagger service
    # -----------------------------
    #
    predict_news_labels:
        build:
            context: ./predict-news-labels/
        image: dockermediacloud/mediacloud-predict-news-labels:latest
        container_name: mc_predict_news_labels
        networks:
            # Accessed by nytlabels_fetch_annotation only
            - net_nytlabels_fetch_annotation_predict_news_labels
        expose:
            - 8080
        deploy:
            # Worker count
            # FIXME disabled while containerization branch is in development because takes up a lot of RAM
            replicas: 0
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 8G

    #
    # Purge PostgreSQL object caches
    # ------------------------------------
    #
    purge_object_caches:
        build:
            context: ./purge-object-caches/
        image: dockermediacloud/mediacloud-purge-object-caches:latest
        container_name: mc_purge_object_caches
        depends_on:
            - postgresql_pgbouncer
        networks:
            # Purges caches on PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256G

    #
    # RabbitMQ
    # --------
    #
    rabbitmq_server:
        build:
            context: ./rabbitmq-server/
        image: dockermediacloud/mediacloud-rabbitmq-server:latest
        container_name: mc_rabbitmq_server
        networks:
            # Exposed to the rest of the services through this network
            - net_rabbitmq
        expose:
            - 5672
            - 15672
        volumes:
            - vol_rabbitmq_data:/var/lib/rabbitmq/mnesia/
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "4"
                    # RAM limit
                    memory: 8G

    #
    # Refresh stats Cron job
    # ----------------------
    #
    cron_refresh_stats:
        build:
            context: ./cron-refresh-stats/
        image: dockermediacloud/mediacloud-cron-refresh-stats:latest
        container_name: mc_cron_refresh_stats
        networks:
            # Refreshes stats on PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Add due media to the rescraping queue Cron job
    # ----------------------------------------------
    #
    cron_rescrape_due_media:
        build:
            context: ./cron-rescrape-due-media/
        image: dockermediacloud/mediacloud-cron-rescrape-due-media:latest
        container_name: mc_cron_rescrape_due_media
        networks:
            # Fetches media to rescrape from PostgreSQL
            - net_postgresql
            # Adds rescraping jobs to RabbitMQ
            - net_rabbitmq
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # (Re)scrape media
    # ----------------
    #
    rescrape_media:
        build:
            context: ./rescrape-media/
        image: dockermediacloud/mediacloud-rescrape-media:latest
        container_name: mc_rescrape_media
        networks:
            # Fetches media to rescrape from PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 2
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 512M

    #
    # Report rescraping changes Cron job
    # ----------------------------------
    #
    cron_rescraping_changes:
        build:
            context: ./cron-rescraping-changes/
        image: dockermediacloud/mediacloud-cron-rescraping-changes:latest
        container_name: mc_cron_rescraping_changes
        networks:
            # Fetches media to rescrape from PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Set media primary language Cron job
    # -----------------------------------
    #
    cron_set_media_primary_language:
        build:
            context: ./cron-set-media-primary-language/
        image: dockermediacloud/mediacloud-cron-set-media-primary-language:latest
        container_name: mc_cron_set_media_primary_language
        networks:
            # Fetches media from PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Set media subject country Cron job
    # -----------------------------------
    #
    cron_set_media_subject_country:
        build:
            context: ./cron-set-media-subject-country/
        image: dockermediacloud/mediacloud-cron-set-media-subject-country:latest
        container_name: mc_cron_set_media_subject_country
        networks:
            # Fetches media from PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Print long running job states
    # -----------------------------
    #
    cron_print_long_running_job_states:
        build:
            context: ./cron-print-long-running-job-states/
        image: dockermediacloud/mediacloud-cron-print-long-running-job-states:latest
        container_name: mc_cron_print_long_running_job_states
        networks:
            # Reads the states from PostgreSQL
            - net_postgresql
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Solr shard
    # ----------
    #
    solr_shard:
        build:
            context: ./solr-shard/
        image: dockermediacloud/mediacloud-solr-shard:latest
        container_name: mc_solr_shard
        depends_on:
            - solr_zookeeper
        networks:
            # Exposed to the rest of the services through this network
            - net_solr
            # Accesses underlying ZooKeeper instance
            - net_solr_zookeeper
        expose:
            - 8983
        volumes:
            - vol_solr_shard_data:/var/lib/solr/
        deploy:
            # Shard count
            replicas: 24
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "4"
                    # RAM limit
                    memory: 24G

    #
    # Solr ZooKeeper
    # --------------
    #
    solr_zookeeper:
        build:
            context: ./solr-zookeeper/
        image: dockermediacloud/mediacloud-solr-zookeeper:latest
        container_name: mc_solr_zookeeper
        networks:
            # Not in "net_solr" because only Solr shards use it
            - net_solr_zookeeper
        expose:
            - 2181
            - 2888
            - 3888
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "2"
                    # RAM limit
                    memory: 2G

    #
    # Extract story links for a topic
    # -------------------------------
    #
    topics_extract_story_links:
        build:
            context: ./topics-extract-story-links/
        image: dockermediacloud/mediacloud-topics-extract-story-links:latest
        container_name: mc_topics_extract_story_links
        depends_on:
            - extract_article_from_html
        networks:
            # Fetches / stores topic links in PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 32
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Fetch link for a topic
    # ----------------------
    #
    topics_fetch_link:
        build:
            context: ./topics-fetch-link/
        image: dockermediacloud/mediacloud-topics-fetch-link:latest
        container_name: mc_topics_fetch_link
        networks:
            # Fetches / stores links in PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 8
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Fetch Twitter URLs
    # ------------------
    #
    topics_fetch_twitter_urls:
        build:
            context: ./topics-fetch-twitter-urls/
        image: dockermediacloud/mediacloud-topics-fetch-twitter-urls:latest
        container_name: mc_topics_fetch_twitter_urls
        environment:
            # Twitter API consumer key
            MC_TWITTER_CONSUMER_KEY: ""
            # Twitter API consumer secret
            MC_TWITTER_CONSUMER_SECRET: ""
            # Twitter API access token
            MC_TWITTER_ACCESS_TOKEN: ""
            # Twitter API access token secret
            MC_TWITTER_ACCESS_TOKEN_SECRET: ""
        networks:
            # Fetches / stores URLs in PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 8
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 256M

    #
    # Mine a topic
    # ------------
    #
    topics_mine:
        build:
            context: ./topics-mine/
        image: dockermediacloud/mediacloud-topics-mine:latest
        container_name: mc_topics_mine
        environment:
            # Crimson Hexagon API key
            MC_CRIMSON_HEXAGON_API_KEY: ""
        networks:
            # Fetches / stores links in PostgreSQL
            - net_postgresql
            # Uses Solr for seed queries and whatnot
            - net_solr
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 4
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Mine a public topic
    # -------------------
    #
    topics_mine_public:
        build:
            context: ./topics-mine-public/
        image: dockermediacloud/mediacloud-topics-mine-public:latest
        container_name: mc_topics_mine_public
        networks:
            # Fetches / stores links in PostgreSQL
            - net_postgresql
            # Uses Solr for seed queries and whatnot
            - net_solr
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 4
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Snapshot a topic
    # ----------------
    #
    topics_snapshot:
        build:
            context: ./topics-snapshot/
        image: dockermediacloud/mediacloud-topics-snapshot:latest
        container_name: mc_topics_snapshot
        environment:
            # Not sure what this is.
            MC_TOPICS_SNAPSHOT_MODEL_REPS: "0"
        networks:
            # Fetches / stores links in PostgreSQL
            - net_postgresql
            # Uses Solr for story matching
            - net_solr
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 2
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Fetch sitemap pages from media
    # ------------------------------
    #
    sitemap_fetch_media_pages:
        build:
            context: ./sitemap-fetch-media-pages/
        image: dockermediacloud/mediacloud-sitemap-fetch-media-pages:latest
        container_name: mc_sitemap_fetch_media_pages
        networks:
            # Stores links to PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Webapp
    # ------
    #
    webapp:
        build:
            context: ./webapp/
        image: dockermediacloud/mediacloud-webapp:latest
        container_name: mc_webapp
        networks:
            # Uses PostgreSQL to fetch / store data
            - net_postgresql
            # Adds Celery jobs
            - net_rabbitmq
            # Uses Solr for searching
            - net_solr
            # Sends email to new / existing users
            - net_postfix
        volumes:
            # Shared with "cron_generate_daily_rss_dumps" container:
            - vol_daily_rss_dumps:/mediacloud_webapp_static/rss_dumps/
        deploy:
            # Only one instance
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "8"
                    # RAM limit
                    memory: 16G

    #
    # Generate word2vec snapshot model
    # ----------------
    #
    word2vec_generate_snapshot_model:
        build:
            context: ./word2vec-generate-snapshot-model/
        image: dockermediacloud/mediacloud-word2vec-generate-snapshot-model:latest
        container_name: mc_word2vec_generate_snapshot_model
        networks:
            # Fetches sentences / stores model in PostgreSQL
            - net_postgresql
            # Celery worker
            - net_rabbitmq
        deploy:
            # Worker count
            replicas: 1
            # Auto-restart on crashes
            restart_policy:
                condition: on-failure
            resources:
                limits:
                    # CPU core limit
                    cpus: "1"
                    # RAM limit
                    memory: 2G

    #
    # Portainer for cluster management
    # --------------------------------
    #
    #portainer:
    #    image: portainer/portainer
    #    container_name: mc_portainer
    #    ports:
    #        # Web interface
    #        - "9000:9000"
    #    command: -H unix:///var/run/docker.sock
    #    volumes:
    #        - /var/run/docker.sock:/var/run/docker.sock
    #        - vol_portainer_data:/data
    #    deploy:
    #        # Only one instance
    #        replicas: 1
    #        resources:
    #            limits:
    #                # CPU core limit
    #                cpus: "1"
    #                # RAM limit
    #                memory: 1G

#
# Networks
# ========
#
networks:

    #
    # PostgreSQL client network
    # -------------------------
    #
    net_postgresql: {}

    #
    # Solr client network
    # -------------------
    #
    net_solr: {}

    #
    # RabbitMQ client network
    # -----------------------
    #
    net_rabbitmq: {}

    #
    # Postfix client network
    # ----------------------
    #
    net_postfix: {}

    #
    # PostgreSQL-PgBouncer internal network
    # -------------------------------------
    #
    net_postgresql_pgbouncer: {}

    #
    # Solr-Zookeeper internal network
    # -------------------------------
    #
    net_solr_zookeeper: {}

    #
    # Postfix-OpenDKIM internal network
    # ---------------------------------
    #
    net_postfix_opendkim: {}

    #
    # NYTLabels fetch annotation - NYT-Based News Tagger service internal network
    # ---------------------------------------------------------------------------
    #
    net_nytlabels_fetch_annotation_predict_news_labels: {}


#
# Volumes
# =======
#
volumes:

    # PostgreSQL server's data
    vol_postgresql_data: {}

    # Solr shard's data
    vol_solr_shard_data: {}

    # RabbitMQ data
    vol_rabbitmq_data: {}

    # Daily RSS dumps
    vol_daily_rss_dumps: {}

    # Portainer data
    #vol_portainer_data: {}

